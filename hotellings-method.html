<!DOCTYPE html>
<html lang="en">
  <head>
    <meta charset="utf-8">
    <meta http-equiv="X-UA-Compatible" content="IE=edge">

    <title>Hotelling's Method &ndash; william-dawson.github.io</title>

    <!-- Meta -->
    <meta name="description" content="william-dawson.github.io &ndash; ">
    <meta name="viewport" content="width=device-width, initial-scale=1.0">

    <!-- Social -->
    <meta property="article:author" content="William Dawson" />
    <meta property="article:section" content="Lessons" />
    <meta property="article:published_time" content="2017-08-21" />

    <meta property="og:type" content="article"/>
    <meta property="og:title" content="Hotelling's Method"/>
    <meta property="og:description" content="Hotelling&#39;s method is a way to compute the inverse of a matrix. I will introduce the method, present a toy implementation, and describe situations where it might be applicable."/>
    <meta property="og:site_name" content="william-dawson.github.io" />
    <meta property="og:url" content="https://william-dawson.github.io/hotellings-method.html"/>

    <meta name="twitter:card" content="summary">
    <meta name="twitter:title" content="Hotelling's Method">
    <meta name="twitter:description" content="Hotelling&#39;s method is a way to compute the inverse of a matrix. I will introduce the method, present a toy implementation, and describe situations where it might be applicable.">
    <meta name="twitter:url" content="https://william-dawson.github.io/hotellings-method.html">

    <!-- Feed -->
    <link rel="alternate" type="application/atom+xml" href="https://william-dawson.github.io/feeds/all.atom.xml" title="william-dawson.github.io Atom Feed" />

    <!-- CSS -->
    <link rel="stylesheet" type="text/css" href="https://fonts.googleapis.com/css?family=Open+Sans:regular,bold">
    <link rel="stylesheet" type="text/css" href="https://william-dawson.github.io/theme/css/w3.css">
    <link rel="stylesheet" type="text/css" href="https://william-dawson.github.io/theme/css/style.css">
    <link rel="stylesheet" type="text/css" href="https://william-dawson.github.io/theme/css/jqcloud.css">
    <link rel="stylesheet" type="text/css" href="https://william-dawson.github.io/theme/css/font-awesome.min.css">
    <link rel="stylesheet" type="text/css" href="https://william-dawson.github.io/theme/css/pygments-highlight-github.css">

    <!-- Icon -->

    <!-- JavaScript -->
    <script src="https://ajax.googleapis.com/ajax/libs/jquery/3.1.0/jquery.min.js"></script>
    <script src="https://william-dawson.github.io/theme/js/jqcloud.min.js"></script>
    <script>
    MathJax = {
      tex: {
        inlineMath: [['$', '$'], ['\\(', '\\)']]
      },
      svg: {
        fontCache: 'global'
      }
    };
    </script>
    <script type="text/javascript" id="MathJax-script" async
      src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-svg.js">
    </script>

  </head>

  <body>
    <div class="w3-row w3-card w3-white">
      <header id="header">
        <a href="https://william-dawson.github.io" id="header-logo" title="Home">WD</a>
        <nav id="header-menu">
          <ul>
            <li class="w3-bottombar w3-border-white w3-hover-border-green"><a href="https://william-dawson.github.io/pages/about.html">About</a></li>
            <li class="w3-bottombar w3-border-white w3-hover-border-green"><a href="https://william-dawson.github.io/pages/projects.html">Projects</a></li>
            <li class="w3-bottombar w3-border-white w3-hover-border-green"><a href="https://william-dawson.github.io/pages/publications.html">Publications</a></li>
            <li class="w3-bottombar w3-border-white w3-hover-border-green"><a href="https://william-dawson.github.io/category/lessons.html">Lessons</a></li>
            <li class="w3-bottombar w3-border-white w3-hover-border-green"><a href="https://william-dawson.github.io/category/personal-blog.html">Personal Blog</a></li>
          </ul>
        </nav>
      </header>
    </div>



    <br><br><br>

    <article>
      <header class="w3-container col-main">
        <h1>Hotelling's Method</h1>
        <div class="post-info">
          <div class="w3-opacity w3-margin-right w3-margin-bottom" style="flex-grow: 1;">
            <span><time datetime="2017-08-21T11:00:00+09:00">Mon 21 August 2017</time> in <a href="https://william-dawson.github.io/category/lessons.html" title="All articles in category Lessons">Lessons</a></span>
          </div>
          <div>
            <span class="w3-tag w3-light-grey w3-text-green w3-hover-green">
              <a href="https://william-dawson.github.io/tag/linear-algebra.html" title="All articles with Linear Algebra tag">#linear algebra</a>
            </span>
          </div>
        </div>
      </header>

      <br>


      <div class="col-main w3-container">
        <section id="content">
          <p>I would like to use this first blog post to introduce Hotelling's method for computing the inverse of a matrix. We'll focus on the symmetric case. First let's begin by asking why we would want to directly compute the inverse of a matrix. After all, one of the first things you'll learn in any numerical linear algebra class is to always avoid explicitly inverting a matrix.</p>
<p>However, in quantum chemistry it's actually fairly normal to compute a matrix inverse. In particular, when solving the generalized eigenvalue problem:</p>
<p>$$\begin{equation}H\phi = \lambda S \phi.\end{equation}$$</p>
<p>We can reduce this generalized eigenvalue problem to the standard eigenvalue problem using the inverse square root of the overlap matrix:</p>
<p>$$\begin{equation}
S^{-\frac{1}{2}}HS^{-\frac{1}{2}}\phi = \lambda \phi.
\end{equation}$$</p>
<p>Performing this calculation is acceptable because we can reuse the inverse over many scf loops, and because the overlap matrix is usually well conditioned. In the canonical density matrix purification method of Palser[1] (which we will probably discuss in more detail later), one also finds the matrix inverse:</p>
<p>$$\begin{equation}
p_0 = \frac{\lambda}{2}(\mu S^{-1} - S^{-1}HS^{-1}) + \frac{1}{2}S^{-1}
\end{equation}$$</p>
<p>where $p_0$ is an initial guess at the density matrix.</p>
<p>Hotelling's method is very simple to implement. It works through the following iteration:</p>
<p>$$\begin{equation}
X_{n+1} = 2X_{n} - X_{n}SX_{n}
\end{equation}$$</p>
<p>where $\lim_{n \to \infty} X_n = S^{-1}$. Palser cites the famous Numerical Recipes book for this method. Disappointingly, it seems that this method is called "Hotelling's Method" because it was invented by statistician Harold Hotelling, and not because it leaves chocolates on your pillows. I've seen some people mention reference [2] as the original paper. Hotelling himself notes that it was "noticed" in reference [3].</p>
<p>The condition for convergence is (from [2]) $ |1 - SX_0 | &lt; 1$. So how should we pick an initial $X_0$? One simple way is to just scale the initial matrix. Consider the eigendecomposition of our initial matrix:</p>
<p>$$\begin{equation}
S = UDU^T.
\end{equation}$$</p>
<p>Now let's plug the decomposition into the convergence condition, with a scaling value $\alpha$:</p>
<p>$$\begin{equation}
|1 - UDU^T\alpha UDU^T | &lt; 1.
\end{equation}$$</p>
<p>$$\begin{equation}
|1 - \alpha DD | &lt; 1.
\end{equation}$$</p>
<p>The effect of multiplying the diagonal matrix of eigenvalues is to square all the eigenvalues. Hence they are all positive. Thus if $\alpha$ is equal to the inverse of the largest eigenvalue squared, we satisfy the equation. The largest eigenvalue can be cheaply computed using the power method.</p>
<p>This is just a simple starting guess that I've introduced, there are better ones out there in the literature, such as the guess in reference [4] which is specific to overlap matrices (homework question: how can we improve our $\alpha$ value for overlap matrices?).</p>
<p>Let's take a look at a simple implementation:</p>
<div class="highlight"><pre><span></span><code><span class="c1"># Libraries</span>
<span class="kn">from</span> <span class="nn">scipy.sparse.linalg</span> <span class="kn">import</span> <span class="n">eigsh</span><span class="p">,</span> <span class="n">norm</span>
<span class="kn">from</span> <span class="nn">scipy.sparse</span> <span class="kn">import</span> <span class="n">identity</span><span class="p">,</span> <span class="n">rand</span>
<span class="kn">from</span> <span class="nn">sys</span> <span class="kn">import</span> <span class="n">argv</span>

<span class="c1"># Input Parameters</span>
<span class="n">dimension</span> <span class="o">=</span> <span class="nb">int</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">1</span><span class="p">])</span>
<span class="n">sparsity</span> <span class="o">=</span> <span class="nb">float</span><span class="p">(</span><span class="n">argv</span><span class="p">[</span><span class="mi">2</span><span class="p">])</span>

<span class="c1"># Initial Matrix</span>
<span class="n">matrix</span> <span class="o">=</span> <span class="n">rand</span><span class="p">(</span><span class="n">dimension</span><span class="p">,</span> <span class="n">dimension</span><span class="p">,</span> <span class="n">density</span><span class="o">=</span><span class="n">sparsity</span><span class="p">,</span> <span class="nb">format</span><span class="o">=</span><span class="s2">&quot;csr&quot;</span><span class="p">)</span>
<span class="n">matrix</span> <span class="o">=</span> <span class="n">matrix</span> <span class="o">+</span> <span class="n">matrix</span><span class="o">.</span><span class="n">T</span>

<span class="c1"># Initial Guess</span>
<span class="n">largest_eigenvalue</span> <span class="o">=</span> <span class="n">eigsh</span><span class="p">(</span><span class="n">matrix</span><span class="p">,</span> <span class="n">k</span><span class="o">=</span><span class="mi">1</span><span class="p">,</span> <span class="n">which</span><span class="o">=</span><span class="s1">&#39;LM&#39;</span><span class="p">,</span>
                           <span class="n">return_eigenvectors</span><span class="o">=</span><span class="kc">False</span><span class="p">)</span>
<span class="n">inverse_mat</span> <span class="o">=</span> <span class="n">matrix</span> <span class="o">*</span> <span class="mf">1.0</span><span class="o">/</span><span class="p">(</span><span class="n">largest_eigenvalue</span><span class="p">[</span><span class="mi">0</span><span class="p">]</span><span class="o">**</span><span class="mi">2</span><span class="p">)</span>

<span class="c1"># Iterate</span>
<span class="k">for</span> <span class="n">i</span> <span class="ow">in</span> <span class="nb">range</span><span class="p">(</span><span class="mi">0</span><span class="p">,</span> <span class="mi">100</span><span class="p">):</span>
    <span class="n">inverse_mat</span> <span class="o">=</span> <span class="mi">2</span><span class="o">*</span><span class="n">inverse_mat</span> <span class="o">-</span> \
                  <span class="n">inverse_mat</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">matrix</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">inverse_mat</span><span class="p">))</span>
  <span class="n">norm_value</span> <span class="o">=</span> <span class="n">norm</span><span class="p">(</span><span class="n">inverse_mat</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span> <span class="o">-</span> <span class="n">identity</span><span class="p">(</span><span class="n">dimension</span><span class="p">))</span>
  <span class="k">if</span> <span class="n">norm_value</span> <span class="o">&lt;</span> <span class="mf">1e-8</span><span class="p">:</span>
    <span class="k">break</span>

<span class="nb">print</span><span class="p">(</span><span class="n">norm</span><span class="p">(</span><span class="n">inverse_mat</span><span class="o">.</span><span class="n">dot</span><span class="p">(</span><span class="n">matrix</span><span class="p">)</span> <span class="o">-</span> <span class="n">identity</span><span class="p">(</span><span class="n">dimension</span><span class="p">)))</span>
</code></pre></div>

<p>The implementation highlights two further features of this algorithm. First,
the main computational kernel is matrix multiplication, which is great for
high performance computing. Second, it's trivial to extend to the sparse case
by simply replacing the dense multiplies with sparse multiplies.</p>
<blockquote>
<p>[1] Palser, Adam HR, and David E. Manolopoulos. "Canonical purification of the
density matrix in electronic-structure theory." Physical Review B 58, no. 19
(1998): 12704.</p>
<p>[2] Hotelling, Harold. "Some new methods in matrix calculation." The Annals
of Mathematical Statistics 14, no. 1 (1943): 1-34.</p>
<p>[3] Frazer, Robert Alexander, William Jolly Duncan, Arthur Roderich Collar,
and A. A. Mullin. "Elementary matrices and some applications to dynamics and
differential equations." American Journal of Physics 29, no. 8 (1961): 555-556.</p>
<p>[4] Ozaki, T. "Efficient recursion method for inverting an overlap matrix."
Physical Review B 64, no. 19 (2001): 195110.</p>
</blockquote>
        </section>

        <br><br><br>

 <!--        <footer>
          <div class="adjust-width">
            <div id="author-block" class="w3-light-grey w3-border">
              <div id="author-info">
                <a href=""><img style="width: 60px; height: 60px;" src="" onerror="this.src='images/avatar.png'" alt="Avatar"></a>
                <div style="margin-left: 20px; margin-top: 15px;">
                  <a href=""><span id="author-name" class="w3-hover-text-dark-grey">William Dawson</span></a>
                  <p id="author-story"></p>
                </div>
              </div>
            </div>
          </div>

          <br><br><br>

          <p style="font-size:10pt; font-style: italic;">Did you like this article? Share it with your friends!</p>
          <div id="share" class="share">
            <a href="http://www.facebook.com/sharer.php?u=https%3A//william-dawson.github.io/hotellings-method.html&amp;t=william-dawson.github.io%3A%20Hotelling%27s%20Method" target="_blank" class="w3-btn w3-indigo">
              <i class="fa fa-facebook"></i> <span>Facebook</span>
            </a>
            <a href="http://twitter.com/share?url=https%3A//william-dawson.github.io/hotellings-method.html&amp;text=william-dawson.github.io%3A%20Hotelling%27s%20Method" target="_blank" class="w3-btn w3-blue">
              <i class="fa fa-twitter"></i> <span>Twitter</span>
            </a>
            <a href="https://plus.google.com/share?url=https%3A//william-dawson.github.io/hotellings-method.html" onclick="javascript:window.open(this.href, '', 'menubar=no,toolbar=no,resizable=yes,scrollbars=yes,height=600,width=600');return false;" class="w3-btn w3-red">
              <i class="fa fa-google-plus"></i> <span>Google</span>
            </a>
          </div>

          <br><br><br>



        </footer> -->
      </div>
    </article>


    <footer id="footer">
      <div id="footer-copyright" class="w3-center w3-small w3-text-grey w3-padding-48">
        <span>&copy;  William Dawson  | <a href="https://william-dawson.github.io/feeds/all.atom.xml">Atom feed <i class="fa fa-rss" aria-hidden="true"></i></a></span>
      </div>
    </footer>



  </body>
</html>